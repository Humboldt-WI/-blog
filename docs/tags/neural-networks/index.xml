<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Neural Networks on Institute of Infomation Systems at HU-Berlin</title>
    <link>https://humboldt-wi.github.io/blog/tags/neural-networks/</link>
    <description>Recent content in Neural Networks on Institute of Infomation Systems at HU-Berlin</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 07 Feb 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://humboldt-wi.github.io/blog/tags/neural-networks/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>BERT</title>
      <link>https://humboldt-wi.github.io/blog/research/information_systems_1920/bert_blog_post/</link>
      <pubDate>Fri, 07 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://humboldt-wi.github.io/blog/research/information_systems_1920/bert_blog_post/</guid>
      <description>Anti Social Online Behaviour Detection with BERT Comparing Bidirectional Encoder Representations from Transformers (BERT) with DistilBERT and Bidirectional Gated Recurrent Unit (BGRU) R. Evtimov - evtimovr@hu-berlin.de
M. Falli - fallimar@hu-berlin.de
A. Maiwald - maiwalam@hu-berlin.de
Introduction Motivation In 2018, a research paper by Devlin et, al. titled “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding” took the machine learning world by storm. Pre-trained on massive amounts of text, BERT, or Bidirectional Encoder Representations from Transformers, presented a new type of natural language model.</description>
    </item>
    
    <item>
      <title>SHOPPER: A Probabalistic Consumer Choice Model</title>
      <link>https://humboldt-wi.github.io/blog/research/information_systems_1920/group3_shopper/</link>
      <pubDate>Fri, 07 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://humboldt-wi.github.io/blog/research/information_systems_1920/group3_shopper/</guid>
      <description>BLOG_POST   /*! * * Twitter Bootstrap * */ /*! * Bootstrap v3.3.7 (http://getbootstrap.com) * Copyright 2011-2016 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE) */ /*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */ html { font-family: sans-serif; -ms-text-size-adjust: 100%; -webkit-text-size-adjust: 100%; } body { margin: 0; } article, aside, details, figcaption, figure, footer, header, hgroup, main, menu, nav, section, summary { display: block; } audio, canvas, progress, video { display: inline-block; vertical-align: baseline; } audio:not([controls]) { display: none; height: 0; } [hidden], template { display: none; } a { background-color: transparent; } a:active, a:hover { outline: 0; } abbr[title] { border-bottom: 1px dotted; } b, strong { font-weight: bold; } dfn { font-style: italic; } h1 { font-size: 2em; margin: 0.</description>
    </item>
    
    <item>
      <title>Deep Learning for Survival Analysis</title>
      <link>https://humboldt-wi.github.io/blog/research/information_systems_1920/group2_survivalanalysis/</link>
      <pubDate>Thu, 06 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://humboldt-wi.github.io/blog/research/information_systems_1920/group2_survivalanalysis/</guid>
      <description>Deep Learning for Survival Analysis Authors: Laura Löschmann, Daria Smorodina  Table of content  Motivation - Business case Introduction to Survival Analysis  2.1 Common terms 2.2 Survival function 2.3 Hazard function   Dataset Standard methods in Survival Analysis  4.1 Kaplan - Meier estimator 4.2 Cox proportional hazards model 4.3 Time-varying Cox regression 4.4 Random survival forests   Deep Learning for Survival Analysis  5.1 DeepSurv 5.</description>
    </item>
    
    <item>
      <title>Causal Neural Networks</title>
      <link>https://humboldt-wi.github.io/blog/research/information_systems_1920/group5_causal_neural_networks/</link>
      <pubDate>Wed, 05 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://humboldt-wi.github.io/blog/research/information_systems_1920/group5_causal_neural_networks/</guid>
      <description>Causal Neural Networks - Optimizing Marketing Spendings Effectivness Hasan Reda Alchahwan, Lukas	Baumann, Darius Schulz
Table of Contents:  Introduction Literature Review Descriptive Analysis of the Dataset Estimation of Treatment Effects considering the checkout amount Estimation of Treatment Effects considering conversion Placebo Experiment Conclusion  1. Introduction Targeting the right customers in marketing campaigns has always been a struggle for marketeers. Data-driven approaches allowed to select targets with the highest probability to buy or the greatest revenue expected, if the costs of the activity deter you from targeting every customer.</description>
    </item>
    
    <item>
      <title>Convolutional Neural Networks - sales forecast</title>
      <link>https://humboldt-wi.github.io/blog/research/information_systems_1819/cnn_sales_forecast/</link>
      <pubDate>Fri, 08 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://humboldt-wi.github.io/blog/research/information_systems_1819/cnn_sales_forecast/</guid>
      <description>Authors: Jakub Kondek, Karim Chennoufi, Kevin Noessler Introduction Motivation The increasing popularity of websites such as Instagram, Facebook or Youtube has lead to an increase in visual data over the last few years. These websites have become part of everyday life for many people and are therefore used excessively. The use of such websites has contributed among other things to enormously increasing amount of visual data in the process. Every day thousands of images and videos are uploaded, making it virtually impossible to analyze them by hand, as the sheer mass of content does not allow it.</description>
    </item>
    
    <item>
      <title>Generative Models</title>
      <link>https://humboldt-wi.github.io/blog/research/information_systems_1819/generativemodels/</link>
      <pubDate>Fri, 08 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://humboldt-wi.github.io/blog/research/information_systems_1819/generativemodels/</guid>
      <description>Authors: Gabriel Blumenstock, Yu Fan, Yang Tian Introduction What are generative models? In machine learning, generative models are used to generate new samples following the same distribution of the original data using unsupervised learning algorithms. Such methods provide a powerful way to detect and analyze enormous information of data, which has been applied to various domains, e.g. images and texts. By learning the statistical latent space of images or stories, the models are able to obtain human experiences and then “create” similar meaningful outputs.</description>
    </item>
    
    <item>
      <title>Text Classification with Hierarchical Attention Network</title>
      <link>https://humboldt-wi.github.io/blog/research/information_systems_1819/group5_han/</link>
      <pubDate>Fri, 08 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://humboldt-wi.github.io/blog/research/information_systems_1819/group5_han/</guid>
      <description>Text Classification with Hierarchical Attention Networks How to assign documents to classes or topics Authors: Maria Kränkel, Hee-Eun Lee - Seminar Information System 18/19  After reading this blog post, you will know:
 What text classification is and what it is used for What hierarchical attention networks are and how their architecture looks like How to classify documents by implementing a hierarchical attention network  Introduction Imagine you work for a company that sells cameras and you would like to find out what customers think about the latest release.</description>
    </item>
    
    <item>
      <title>Crime and Neural Nets</title>
      <link>https://humboldt-wi.github.io/blog/research/information_systems_1819/02lstmgruandbeyond/</link>
      <pubDate>Thu, 07 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://humboldt-wi.github.io/blog/research/information_systems_1819/02lstmgruandbeyond/</guid>
      <description>Crime and Neural Nets&amp;#182;Introducing Recurrent Neural Networks with Long-Short-Term Memory and Gated Recurrent Unit to predict reported Crime Incidents&amp;#182;Carolin Kunze, Marc Scheu, Thomas Siskos&amp;#182;Several police departments across the Unites States have been experimenting with software for crime prdiction. This started a controversial debate: Critics are questioning the predictiv power of the underlying machine learning models and point out biases towards certain crime typs and neighborhoods. We took this as occacion to look into the publicly available crime records of the city of chicago.</description>
    </item>
    
    <item>
      <title>Neural Network Fundamentals</title>
      <link>https://humboldt-wi.github.io/blog/research/information_systems_1718/01neuralnetworkfundamentals/</link>
      <pubDate>Thu, 14 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://humboldt-wi.github.io/blog/research/information_systems_1718/01neuralnetworkfundamentals/</guid>
      <description>Neural Network Fundamentals Authors: Mahdi Bayat, Denis Augusto Pinto Maciel, Roman Proskalovich This blog post is a guide to help readers build a neural network from the very basics. It starts with an introduction to the concept of a neural networks concept and its early development. A step-by-step coding tutorial follows, through which relevant concepts are illustrated. Later in the post, there is also an introduction on how to build neural networks in Keras.</description>
    </item>
    
    <item>
      <title>Neural Networks into Production</title>
      <link>https://humboldt-wi.github.io/blog/research/information_systems_1718/09deeplearningintoproduction/</link>
      <pubDate>Thu, 14 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://humboldt-wi.github.io/blog/research/information_systems_1718/09deeplearningintoproduction/</guid>
      <description>Neural Networks into Production Authors: Mahdi Bayat, Denis Augusto Pinto Maciel, Roman Proskalovich Motivation Training and tuning machine learning model is a hard task. There are many variables involved that can make or break your results. However, also very important is, after fine tuning your model, to be able to deploy it, so it can be accessed by other researchers, developers and applications.
A very common way to accomplish that is by using an API.</description>
    </item>
    
    <item>
      <title>Sample Post</title>
      <link>https://humboldt-wi.github.io/blog/research/instruction/00samplepost/</link>
      <pubDate>Thu, 14 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://humboldt-wi.github.io/blog/research/instruction/00samplepost/</guid>
      <description>TEST #hugo
import numpy as np import pandas as pd 2+3 A Gentle Introduction to Neural Network Fundamentals There are handwritten numbers that you want computer to correctly clasify. It would be an easy task for a person but an extremely complicated one for a machine, especially, if you want to use some traditional prediction model, like linear regression. Even though the computer is faster than the human brain in numeric computations, the brain far outperforms the computer in some tasks.</description>
    </item>
    
  </channel>
</rss>